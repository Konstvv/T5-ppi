{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.shutdown()\n",
    "\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins in clusters: 7709111\n",
      "Number of clusters: 498526\n"
     ]
    }
   ],
   "source": [
    "with open('pickles/fasta_dict.pkl', 'rb') as f:\n",
    "    fasta_records = pickle.load(f)\n",
    "with open('pickles/clusters.pkl', 'rb') as f:\n",
    "    clusters = pickle.load(f)\n",
    "print('Proteins in clusters: {}'.format(len(clusters)))\n",
    "print('Number of clusters: {}'.format(len(set(clusters.values()))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "interactions_raw = pd.read_csv('string12.0_combined_score_900.tsv', sep=' ', usecols=['protein1', 'protein2', 'combined_score'])\n",
    "interactions_raw['clusters'] = interactions_raw.apply(lambda row: (clusters[row['protein1']], clusters[row['protein2']]), axis=1)\n",
    "interactions = interactions_raw[interactions_raw['combined_score'] > 900]\n",
    "interactions['score'] = 1\n",
    "interactions = interactions.drop(columns='combined_score')\n",
    "# interactions.to_csv('positives.tsv', sep='\\t', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "2024-08-20 18:12:50,260\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "\u001B[33m(raylet)\u001B[0m /Users/volzhenin/PycharmProjects/T5-ppi/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "\u001B[33m(raylet)\u001B[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         protein1        protein2  \\\n",
      "0  23.BEL05_00045  23.BEL05_15465   \n",
      "1  23.BEL05_00045  23.BEL05_07675   \n",
      "2  23.BEL05_00090  23.BEL05_00095   \n",
      "3  23.BEL05_00095  23.BEL05_00090   \n",
      "4  23.BEL05_00145  23.BEL05_13290   \n",
      "\n",
      "                                            clusters  score  \n",
      "0          ('1492922.GY26_20280', '28176.CF66_7091')      1  \n",
      "1         ('1492922.GY26_20280', '67801.A0A1B0C7F8')      1  \n",
      "2     ('1798274.A3E87_01195', '1262974.BN779_00805')      1  \n",
      "3     ('1262974.BN779_00805', '1798274.A3E87_01195')      1  \n",
      "4  ('286419.ENSCAFP00020032892', '278944.A0A4Z1IE...      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(raylet)\u001B[0m Spilled 3734 MiB, 13 objects, write throughput 1991 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001B[36m(raylet)\u001B[0m Spilled 5237 MiB, 18 objects, write throughput 2160 MiB/s.\n",
      "\u001B[33m(raylet)\u001B[0m /Users/volzhenin/PycharmProjects/T5-ppi/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\u001B[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "\u001B[33m(raylet)\u001B[0m   warnings.warn(\u001B[32m [repeated 7x across cluster]\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "interactions = pd.read_csv('positives.tsv', sep='\\t', header=None, names=['protein1', 'protein2', 'clusters', 'score'])\n",
    "print(interactions.head())\n",
    "unique_clusters = set(interactions['clusters'].values)\n",
    "interactions = interactions.drop(columns='clusters')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `df.groupby(categorical_by, sort=False)` implementation has mismatches with pandas:\n",
      "the groupby keys will be sorted anyway, although the 'sort=False' was passed. See the following issue for more details: https://github.com/modin-project/modin/issues/3571.\n",
      "UserWarning: <function Series.to_dict> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "UserWarning: <function Series.to_dict> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "proteins_dict1 = interactions['protein1'].value_counts().to_dict()\n",
    "proteins_dict2 = interactions['protein2'].value_counts().to_dict()\n",
    "proteins_dict = {k: proteins_dict1.get(k, 0) + proteins_dict2.get(k, 0) for k in set(proteins_dict1) | set(proteins_dict2)}\n",
    "# proteins_list = set(interactions['protein1'].values) | set(interactions['protein2'].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compare_to_unique(row):\n",
    "    cluster1 = clusters[row['protein1']]\n",
    "    cluster2 = clusters[row['protein2']]\n",
    "\n",
    "    return (cluster1, cluster2) in unique_clusters or (cluster2, cluster1) in unique_clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40300000it [00:10, 3803851.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial file length: 40300000\n",
      "Required file length: 723379960\n",
      "Pairs left: 683079960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60300000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m chuncksize \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20000000\u001B[39m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m file_len \u001B[38;5;241m<\u001B[39m positive_len \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m:\n\u001B[0;32m---> 16\u001B[0m     negative_pairs \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprotein1\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprots\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchuncksize\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprotein2\u001B[39m\u001B[38;5;124m'\u001B[39m: random\u001B[38;5;241m.\u001B[39mchoices(prots, weights\u001B[38;5;241m=\u001B[39mweights, k\u001B[38;5;241m=\u001B[39mchuncksize)})\n\u001B[1;32m     17\u001B[0m     negative_pairs \u001B[38;5;241m=\u001B[39m negative_pairs[\u001B[38;5;241m~\u001B[39mnegative_pairs\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m row: compare_to_unique(row), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)]\n\u001B[1;32m     18\u001B[0m     negative_pairs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/random.py:505\u001B[0m, in \u001B[0;36mRandom.choices\u001B[0;34m(self, population, weights, cum_weights, k)\u001B[0m\n\u001B[1;32m    503\u001B[0m bisect \u001B[38;5;241m=\u001B[39m _bisect\n\u001B[1;32m    504\u001B[0m hi \u001B[38;5;241m=\u001B[39m n \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 505\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [population[bisect(cum_weights, random() \u001B[38;5;241m*\u001B[39m total, \u001B[38;5;241m0\u001B[39m, hi)]\n\u001B[1;32m    506\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _repeat(\u001B[38;5;28;01mNone\u001B[39;00m, k)]\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/random.py:505\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    503\u001B[0m bisect \u001B[38;5;241m=\u001B[39m _bisect\n\u001B[1;32m    504\u001B[0m hi \u001B[38;5;241m=\u001B[39m n \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 505\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [population[\u001B[43mbisect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcum_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhi\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[1;32m    506\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _repeat(\u001B[38;5;28;01mNone\u001B[39;00m, k)]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "positive_len = len(interactions)\n",
    "file_len = 0\n",
    "if os.path.exists('negatives.tsv'):\n",
    "    with open('negatives.tsv', 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            file_len += 1\n",
    "print('Initial file length: {}'.format(file_len))\n",
    "print('Required file length: {}'.format(positive_len * 10))\n",
    "print('Pairs left: {}'.format(positive_len * 10 - file_len))\n",
    "\n",
    "prots = list(proteins_dict.keys())\n",
    "weights = proteins_dict.values()\n",
    "\n",
    "chuncksize = 20000000\n",
    "while file_len < positive_len * 10:\n",
    "    negative_pairs = pd.DataFrame({'protein1': random.choices(prots, weights=weights, k=chuncksize), 'protein2': random.choices(prots, weights=weights, k=chuncksize)})\n",
    "    negative_pairs = negative_pairs[~negative_pairs.apply(lambda row: compare_to_unique(row), axis=1)]\n",
    "    negative_pairs['score'] = 0\n",
    "    negative_pairs.to_csv('negatives.tsv', sep='\\t', index=False, header=False, mode='a')\n",
    "    file_len += len(negative_pairs)\n",
    "    print(file_len)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negatives = pd.read_csv('negatives.tsv', sep='\\t', header=None, names=['protein1', 'protein2', 'score'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72337996it [00:46, 1557749.41it/s]\n",
      "732400000it [04:06, 2971483.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# positive_len = 72337996\n",
    "with open('all_900.tsv', 'w') as f:\n",
    "    with open('positives.tsv', 'r') as fr:\n",
    "        for line in tqdm(fr):\n",
    "            args = line.strip().split('\\t')\n",
    "            f.write('\\t'.join([args[0], args[1], args[-1]])+'\\n')\n",
    "    leng = 0\n",
    "    with open('negatives.tsv', 'r') as fr:\n",
    "        for line in tqdm(fr):\n",
    "            f.write(line.strip()+'\\n')\n",
    "            leng += 1\n",
    "            if leng > positive_len * 10:\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "794718562it [02:05, 6356001.51it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('all_900.tsv', 'r') as f:\n",
    "    with open('all_900_train.tsv', 'w') as f_train:\n",
    "        with open('all_900_test.tsv', 'w') as f_test:\n",
    "            for line in tqdm(f):\n",
    "                if random.random() < 1000000 / positive_len / 11:\n",
    "                    f_test.write(line)\n",
    "                else:\n",
    "                    f_train.write(line)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
